{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748d9159-79b0-4564-8209-7243be891727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForMaskedLM\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "#df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "path ='stas/train.tsv'\n",
    "train_df = pd.read_csv(path,sep='\\t')\n",
    "\n",
    "path ='stas/dev.tsv'\n",
    "val_df = pd.read_csv(path,sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output_file = 'stas_aug'\n",
    "os.makedirs(output_file, exist_ok=True)\n",
    "num_aug = 6\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2e3c93-e2ef-4097-975d-d65b65259d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated augmented sentences with eda for to stas_aug/eda.tsv with num_aug=6\n"
     ]
    }
   ],
   "source": [
    "from eda import *\n",
    "#eda\n",
    "file_name = 'eda.tsv'\n",
    "output_dir = os.path.join(output_file, file_name)\n",
    "gen_eda(train_df,output_dir , alpha=alpha, num_aug=num_aug , reverse = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f21a56c1-d803-49c5-b0b2-a0a2d405f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 6228/6228 [28:31:29<00:00, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated augmented sentences with eda for to stas_aug/backtranslate.tsv with num_aug=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#backtranslate\n",
    "from backtranslation import *\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "first_model_name = 'Helsinki-NLP/opus-mt-en-ROMANCE'\n",
    "\n",
    "# Get the tokenizer\n",
    "first_model_tkn = MarianTokenizer.from_pretrained(first_model_name)\n",
    "\n",
    "# Load the pretrained model based on the name\n",
    "first_model = MarianMTModel.from_pretrained(first_model_name)\n",
    "\n",
    "\n",
    "second_model_name = 'Helsinki-NLP/opus-mt-ROMANCE-en'\n",
    "\n",
    "# Get the tokenizer\n",
    "second_model_tkn = MarianTokenizer.from_pretrained(second_model_name)\n",
    "\n",
    "# Load the pretrained model based on the name\n",
    "second_model = MarianMTModel.from_pretrained(second_model_name)\n",
    "\n",
    "\n",
    "\n",
    "file_name = 'backtranslate.tsv'\n",
    "output_dir = os.path.join(output_file, file_name)\n",
    "gen_backtranslation(first_model,second_model,first_model_tkn,second_model_tkn, train_df,output_dir , num_aug=num_aug )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1fc34cd-658e-4bd9-922c-a208eb0ae7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.0.6_1/libexec/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbert training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                              | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 3.1957479238510134\n",
      "avg_loss: 5.742271683216095\n",
      "avg_loss: 8.264714543819428\n",
      "avg_loss: 10.83595739364624\n",
      "avg_loss: 13.186725118160247\n",
      "avg_loss: 15.623747955560685\n",
      "avg_loss: 18.133400317430496\n",
      "avg_loss: 20.50619668364525\n",
      "avg_loss: 22.89816270709038\n",
      "avg_loss: 25.39960588335991\n",
      "avg_loss: 27.866649867296218\n",
      "avg_loss: 30.294706736803054\n",
      "avg_loss: 32.91315194964409\n",
      "avg_loss: 35.225190378427506\n",
      "avg_loss: 37.70077576041221\n",
      "Saving model. Best dev so far 193.44961881637573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|████▎                             | 1/8 [17:29<2:02:26, 1049.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 1.1497634381055832\n",
      "avg_loss: 2.3520321542024614\n",
      "avg_loss: 3.606960774064064\n",
      "avg_loss: 4.737216963768005\n",
      "avg_loss: 5.846998935341835\n",
      "avg_loss: 7.126105470657349\n",
      "avg_loss: 8.376834517717361\n",
      "avg_loss: 9.613229300379754\n",
      "avg_loss: 10.849126465916633\n",
      "avg_loss: 12.102237426042556\n",
      "avg_loss: 13.428392273187637\n",
      "avg_loss: 14.688194401264191\n",
      "avg_loss: 16.082523586153982\n",
      "avg_loss: 17.382479215860368\n",
      "avg_loss: 18.73142382979393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|████████▊                          | 2/8 [33:07<1:38:25, 984.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 0.4457260738313198\n",
      "avg_loss: 0.9785194791853428\n",
      "avg_loss: 1.5415838567912579\n",
      "avg_loss: 2.0842393255233764\n",
      "avg_loss: 2.5952030752599238\n",
      "avg_loss: 3.121086344867945\n",
      "avg_loss: 3.6453360176086425\n",
      "avg_loss: 4.162353466749192\n",
      "avg_loss: 4.740421164482832\n",
      "avg_loss: 5.215536932311952\n",
      "avg_loss: 5.898764607571065\n",
      "avg_loss: 6.432057412527501\n",
      "avg_loss: 7.036820000521839\n",
      "avg_loss: 7.544643342904746\n",
      "avg_loss: 8.084834032170475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|████████████▊                     | 3/8 [52:04<1:27:48, 1053.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 0.2289782154560089\n",
      "avg_loss: 0.45554518211632966\n",
      "avg_loss: 0.6885855252668261\n",
      "avg_loss: 0.8908224575594068\n",
      "avg_loss: 1.0752311894111335\n",
      "avg_loss: 1.2716572232544423\n",
      "avg_loss: 1.4581953276693822\n",
      "avg_loss: 1.6649724186956882\n",
      "avg_loss: 1.8464331326074899\n",
      "avg_loss: 2.0724659812264146\n",
      "avg_loss: 2.318057753574103\n",
      "avg_loss: 2.564128357172012\n",
      "avg_loss: 2.7898583082854747\n",
      "avg_loss: 3.0004730651527645\n",
      "avg_loss: 3.2500492976605893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|████████████████                | 4/8 [1:34:40<1:49:47, 1646.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 0.08371387783437967\n",
      "avg_loss: 0.1777919083274901\n",
      "avg_loss: 0.26088040607981383\n",
      "avg_loss: 0.36302757534198465\n",
      "avg_loss: 0.46209780699573455\n",
      "avg_loss: 0.5599034605082125\n",
      "avg_loss: 0.6629162933398038\n",
      "avg_loss: 0.7575370684731751\n",
      "avg_loss: 0.8453213428799063\n",
      "avg_loss: 0.9483074418548495\n",
      "avg_loss: 1.0710400593373925\n",
      "avg_loss: 1.1795561436284334\n",
      "avg_loss: 1.265145686622709\n",
      "avg_loss: 1.3578553166240455\n",
      "avg_loss: 1.4516570532880724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|████████████████████            | 5/8 [2:40:09<2:03:29, 2469.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 0.06938049783930182\n",
      "avg_loss: 0.1378468144312501\n",
      "avg_loss: 0.1788443505577743\n",
      "avg_loss: 0.2610830863006413\n",
      "avg_loss: 0.34145967874675986\n",
      "avg_loss: 0.4510618541389704\n",
      "avg_loss: 0.5147441478911787\n",
      "avg_loss: 0.5935849867295474\n",
      "avg_loss: 0.6877271207328886\n",
      "avg_loss: 0.7843344106618315\n",
      "avg_loss: 0.8747821197658777\n",
      "avg_loss: 0.9744008611887693\n",
      "avg_loss: 1.044326324844733\n",
      "avg_loss: 1.1260156678501516\n",
      "avg_loss: 1.2046462224330754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|████████████████████████        | 6/8 [2:58:15<1:06:38, 1999.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 0.0586495131906122\n",
      "avg_loss: 0.11112248203717172\n",
      "avg_loss: 0.17272986344993113\n",
      "avg_loss: 0.2365343174152076\n",
      "avg_loss: 0.30142040938138964\n",
      "avg_loss: 0.3558576086629182\n",
      "avg_loss: 0.41182237412780526\n",
      "avg_loss: 0.45912651335820553\n",
      "avg_loss: 0.5122632200829684\n",
      "avg_loss: 0.5780849885754287\n",
      "avg_loss: 0.6566520255152136\n",
      "avg_loss: 0.7227441331651062\n",
      "avg_loss: 0.8020714976172895\n",
      "avg_loss: 0.8763500942476093\n",
      "avg_loss: 0.9548070780001581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  88%|█████████████████████████████▊    | 7/8 [3:15:09<27:57, 1677.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 0.07834688868373632\n",
      "avg_loss: 0.15696410983800888\n",
      "avg_loss: 0.23839070778340102\n",
      "avg_loss: 0.2761397501081228\n",
      "avg_loss: 0.3527383102104068\n",
      "avg_loss: 0.4311690295115113\n",
      "avg_loss: 0.4993359205732122\n",
      "avg_loss: 0.5688388651190326\n",
      "avg_loss: 0.6366188036231324\n",
      "avg_loss: 0.6968086048448459\n",
      "avg_loss: 0.7566565830400214\n",
      "avg_loss: 0.836978270704858\n",
      "avg_loss: 0.9261725006205961\n",
      "avg_loss: 0.99282817018684\n",
      "avg_loss: 1.0655595614993945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████| 8/8 [3:32:26<00:00, 1593.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "779it [04:22,  2.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from cbert import *\n",
    "#cbert\n",
    "\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL,\n",
    "                                              do_lower_case=True,\n",
    "                                              cache_dir='transformers_cache')\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained(BERT_MODEL,\n",
    "                                        cache_dir='transformers_cache')\n",
    "\n",
    "file_name = 'cbert.tsv'\n",
    "train_cbert_and_augment(model, tokenizer,train_df,val_df,output=output_file,file_name=file_name\n",
    "                            ,seed = 1234,max_seq_length = 64,sample_num=num_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6596b13a-1600-40e7-883c-8d1e945682e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.0.6_1/libexec/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cgpt2 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                              | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 3.961678771972656\n",
      "avg_loss: 7.4761397695541385\n",
      "avg_loss: 10.927530794143676\n",
      "avg_loss: 14.341821131706238\n",
      "avg_loss: 17.708639631271364\n",
      "avg_loss: 21.10231376171112\n",
      "avg_loss: 24.447123136520386\n",
      "Epoch 0, Dev loss 129.91488409042358\n",
      "Saving model. Best dev so far 129.91488409042358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|████▍                              | 1/8 [10:58<1:16:48, 658.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 3.153920502662659\n",
      "avg_loss: 6.302988715171814\n",
      "avg_loss: 9.414281549453735\n",
      "avg_loss: 12.579243836402894\n",
      "avg_loss: 15.684745717048646\n",
      "avg_loss: 18.78993953704834\n",
      "avg_loss: 21.8742227268219\n",
      "Epoch 1, Dev loss 128.6148397922516\n",
      "Saving model. Best dev so far 128.6148397922516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|█████████▎                           | 2/8 [19:39<57:45, 577.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 2.926469268798828\n",
      "avg_loss: 5.86198468208313\n",
      "avg_loss: 8.783524236679078\n",
      "avg_loss: 11.723692002296447\n",
      "avg_loss: 14.683991260528565\n",
      "avg_loss: 17.619119815826416\n",
      "avg_loss: 20.604969062805175\n",
      "Epoch 2, Dev loss 128.3790090084076\n",
      "Saving model. Best dev so far 128.3790090084076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|█████████████▉                       | 3/8 [28:25<46:11, 554.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 2.7621064805984497\n",
      "avg_loss: 5.5323617553710935\n",
      "avg_loss: 8.31735445022583\n",
      "avg_loss: 11.122434401512146\n",
      "avg_loss: 13.92583134174347\n",
      "avg_loss: 16.737228145599364\n",
      "avg_loss: 19.52341519832611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|██████████████████▌                  | 4/8 [37:23<36:30, 547.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Dev loss 129.00188851356506\n",
      "avg_loss: 2.5985759925842284\n",
      "avg_loss: 5.253607006072998\n",
      "avg_loss: 7.869997220039368\n",
      "avg_loss: 10.515979385375976\n",
      "avg_loss: 13.183161993026733\n",
      "avg_loss: 15.856100578308105\n",
      "avg_loss: 18.518156781196595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|███████████████████████▏             | 5/8 [46:47<27:40, 553.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Dev loss 130.54644227027893\n",
      "avg_loss: 2.4470490264892577\n",
      "avg_loss: 4.947133755683899\n",
      "avg_loss: 7.449402265548706\n",
      "avg_loss: 9.933221101760864\n",
      "avg_loss: 12.472512774467468\n",
      "avg_loss: 15.007493901252747\n",
      "avg_loss: 17.53350995540619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████████████████████████▊         | 6/8 [55:29<18:06, 543.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Dev loss 132.55505967140198\n",
      "avg_loss: 2.32115026473999\n",
      "avg_loss: 4.681991991996765\n",
      "avg_loss: 7.048061728477478\n",
      "avg_loss: 9.437093124389648\n",
      "avg_loss: 11.8296302318573\n",
      "avg_loss: 14.209065551757812\n",
      "avg_loss: 16.61457414627075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  88%|████████████████████████████    | 7/8 [7:24:29<2:13:15, 7995.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Dev loss 135.37924313545227\n",
      "avg_loss: 2.1629501605033874\n",
      "avg_loss: 4.393239943981171\n",
      "avg_loss: 6.61767431974411\n",
      "avg_loss: 8.866700232028961\n",
      "avg_loss: 11.125895650386811\n",
      "avg_loss: 13.384941656589508\n",
      "avg_loss: 15.651327240467072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████████| 8/8 [10:00:21<00:00, 4502.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Dev loss 137.90889525413513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from cgpt2 import *\n",
    "#gpt2\n",
    "\n",
    "GPT2_MODEL = 'gpt2'\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(GPT2_MODEL,\n",
    "                                              do_lower_case=True,\n",
    "                                          cache_dir='transformers_cache')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(GPT2_MODEL,\n",
    "                                        cache_dir='transformers_cache')\n",
    "\n",
    "\n",
    "\n",
    "file_name = 'gpt2.tsv'\n",
    "\n",
    "train_cmodgpt2_and_augment(model,tokenizer,train_df,val_df,output=output_file,\n",
    "                           file_name=file_name,seed = 1234,max_seq_length = 64,sample_num=num_aug,num_train_epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17da1bf0-115b-4a76-b719-55b5d41995a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "236e1fd1-f4b2-43a9-910c-bdcf74aab351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/opt/homebrew/Cellar/jupyterlab/4.0.6_1/libexec/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cPosGpt2 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                              | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 3.9518698167800905\n",
      "avg_loss: 7.5053951978683475\n",
      "avg_loss: 10.936351990699768\n",
      "avg_loss: 14.334213070869446\n",
      "avg_loss: 17.7394860124588\n",
      "avg_loss: 21.077692060470582\n",
      "avg_loss: 24.415390257835387\n",
      "Epoch 0, Dev loss 129.5145218372345\n",
      "Saving model. Best dev so far 129.5145218372345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|████▎                             | 1/8 [21:34<2:31:00, 1294.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 3.143104786872864\n",
      "avg_loss: 6.270861029624939\n",
      "avg_loss: 9.432158741950989\n",
      "avg_loss: 12.534587445259094\n",
      "avg_loss: 15.6348233127594\n",
      "avg_loss: 18.750471067428588\n",
      "avg_loss: 21.859485726356507\n",
      "Epoch 1, Dev loss 128.21618556976318\n",
      "Saving model. Best dev so far 128.21618556976318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|████████▌                         | 2/8 [42:54<2:08:34, 1285.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 2.921581840515137\n",
      "avg_loss: 5.849713387489319\n",
      "avg_loss: 8.779400687217713\n",
      "avg_loss: 11.771110587120056\n",
      "avg_loss: 14.710669560432434\n",
      "avg_loss: 17.654980626106262\n",
      "avg_loss: 20.600343656539916\n",
      "Epoch 2, Dev loss 128.04809093475342\n",
      "Saving model. Best dev so far 128.04809093475342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|████████████                    | 3/8 [1:01:31<1:40:45, 1209.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 2.7812079906463625\n",
      "avg_loss: 5.559422583580017\n",
      "avg_loss: 8.33236268043518\n",
      "avg_loss: 11.145090069770813\n",
      "avg_loss: 13.956797409057618\n",
      "avg_loss: 16.74525574207306\n",
      "avg_loss: 19.52193440437317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|████████████████                | 4/8 [1:18:16<1:15:12, 1128.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Dev loss 128.72420239448547\n",
      "avg_loss: 2.5960386323928835\n",
      "avg_loss: 5.233736119270325\n",
      "avg_loss: 7.876192355155945\n",
      "avg_loss: 10.52570390701294\n",
      "avg_loss: 13.182319970130921\n",
      "avg_loss: 15.85283793926239\n",
      "avg_loss: 18.521780819892882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|█████████████████████▎            | 5/8 [1:38:35<58:03, 1161.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Dev loss 130.38134360313416\n",
      "avg_loss: 2.481374020576477\n",
      "avg_loss: 4.964682879447937\n",
      "avg_loss: 7.448491635322571\n",
      "avg_loss: 9.977910742759704\n",
      "avg_loss: 12.501165232658387\n",
      "avg_loss: 15.001314525604249\n",
      "avg_loss: 17.52684016227722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|█████████████████████████▌        | 6/8 [2:01:35<41:10, 1235.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Dev loss 132.54323482513428\n",
      "avg_loss: 2.3195648097991945\n",
      "avg_loss: 4.7073150157928465\n",
      "avg_loss: 7.055639338493347\n",
      "avg_loss: 9.420111093521118\n",
      "avg_loss: 11.800248222351074\n",
      "avg_loss: 14.187536883354188\n",
      "avg_loss: 16.58380169391632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  88%|█████████████████████████████▊    | 7/8 [2:25:13<21:35, 1295.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Dev loss 135.235013961792\n",
      "avg_loss: 2.195816388130188\n",
      "avg_loss: 4.418414678573608\n",
      "avg_loss: 6.635085299015045\n",
      "avg_loss: 8.908379032611847\n",
      "avg_loss: 11.167595345973968\n",
      "avg_loss: 13.415624339580535\n",
      "avg_loss: 15.652224259376526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████| 8/8 [2:50:50<00:00, 1281.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Dev loss 138.24535584449768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 per sentence is augmented, file is saved in <_io.TextIOWrapper name='stas_aug/cposgpt2.tsv' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "from cPosGpt2 import *\n",
    "#postag gpt2\n",
    "GPT2_MODEL = 'gpt2'\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(GPT2_MODEL,\n",
    "                                              do_lower_case=True,\n",
    "                                          cache_dir='transformers_cache')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(GPT2_MODEL,\n",
    "                                        cache_dir='transformers_cache')\n",
    "\n",
    "\n",
    "file_name = 'cposgpt2.tsv'\n",
    "\n",
    "train_cposgpt2_and_augment(model,tokenizer,train_df,val_df,output=output_file,\n",
    "                           file_name=file_name,seed = 1234,max_seq_length = 64,sample_num=num_aug,num_train_epochs=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a7758f0-817a-4a75-b14d-f68d79c1e0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.0.6_1/libexec/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cPosGpt2 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 3.5991578102111816\n",
      "avg_loss: 6.726917667388916\n",
      "avg_loss: 9.819334082603454\n",
      "avg_loss: 12.86300371646881\n",
      "avg_loss: 15.855971965789795\n",
      "avg_loss: 18.73064715862274\n",
      "avg_loss: 21.623071513175965\n",
      "avg_loss: 24.550620951652526\n",
      "avg_loss: 27.384980616569518\n",
      "avg_loss: 30.21378520488739\n",
      "avg_loss: 33.00791392326355\n",
      "avg_loss: 35.89558188438416\n",
      "avg_loss: 38.665161008834836\n",
      "avg_loss: 41.48594256401062\n",
      "avg_loss: 44.372859263420104\n",
      "avg_loss: 47.198714509010316\n",
      "avg_loss: 50.05055787086487\n",
      "avg_loss: 52.80361756801605\n",
      "avg_loss: 55.53465080738068\n",
      "avg_loss: 58.293518357276916\n",
      "avg_loss: 60.98481091976166\n",
      "avg_loss: 63.69160889148712\n",
      "avg_loss: 66.34433648586273\n",
      "avg_loss: 69.0024987411499\n",
      "avg_loss: 71.75816399574279\n",
      "avg_loss: 74.41363979578018\n",
      "avg_loss: 77.12421842813492\n",
      "avg_loss: 79.85374779939652\n",
      "avg_loss: 82.54978224039078\n",
      "avg_loss: 85.15249268770218\n",
      "avg_loss: 87.79334936857224\n",
      "avg_loss: 90.4720177769661\n",
      "avg_loss: 93.16835798501968\n",
      "avg_loss: 95.85280269861221\n",
      "avg_loss: 98.45016186952591\n",
      "avg_loss: 101.0410716509819\n",
      "avg_loss: 103.61274305820466\n",
      "avg_loss: 106.2444646024704\n",
      "avg_loss: 108.81931404590607\n",
      "Epoch 0, Dev loss 168.85555052757263\n",
      "Saving model. Best dev so far 168.85555052757263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|████████████████                | 1/2 [1:04:58<1:04:58, 3898.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 2.4797953224182128\n",
      "avg_loss: 4.958498864173889\n",
      "avg_loss: 7.394961469173431\n",
      "avg_loss: 9.879613959789276\n",
      "avg_loss: 12.329237172603607\n",
      "avg_loss: 14.813180401325226\n",
      "avg_loss: 17.282046604156495\n",
      "avg_loss: 19.722372069358826\n",
      "avg_loss: 22.169961009025574\n",
      "avg_loss: 24.567985877990722\n",
      "avg_loss: 27.006733140945435\n",
      "avg_loss: 29.46720698595047\n",
      "avg_loss: 31.9124920129776\n",
      "avg_loss: 34.330031688213346\n",
      "avg_loss: 36.739429805278775\n",
      "avg_loss: 39.206257636547086\n",
      "avg_loss: 41.62844923734665\n",
      "avg_loss: 44.03088268756866\n",
      "avg_loss: 46.44517509698868\n",
      "avg_loss: 48.87452157497406\n",
      "avg_loss: 51.29308076381683\n",
      "avg_loss: 53.72401995658875\n",
      "avg_loss: 56.04833187818527\n",
      "avg_loss: 58.43888867139816\n",
      "avg_loss: 60.78876885652542\n",
      "avg_loss: 63.18839158296585\n",
      "avg_loss: 65.51805891752242\n",
      "avg_loss: 67.8921299815178\n",
      "avg_loss: 70.221968126297\n",
      "avg_loss: 72.57038066387176\n",
      "avg_loss: 74.97791658639908\n",
      "avg_loss: 77.44854725599289\n",
      "avg_loss: 79.80648236989975\n",
      "avg_loss: 82.16857852220535\n",
      "avg_loss: 84.49405368328094\n",
      "avg_loss: 86.7988510131836\n",
      "avg_loss: 89.08109822034835\n",
      "avg_loss: 91.36569474220276\n",
      "avg_loss: 93.67293246746063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████| 2/2 [2:09:01<00:00, 3870.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Dev loss 176.80855989456177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/homebrew/Cellar/jupyterlab/4.0.6_1/libexec/lib/python3.11/site-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 68, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Cellar/jupyterlab/4.0.6_1/libexec/lib/python3.11/site-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 64, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Cellar/jupyterlab/4.0.6_1/libexec/lib/python3.11/site-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 65, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 per sentence is augmented, file is saved in <_io.TextIOWrapper name='stas_aug/posgpt2_eda.tsv' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "from cPosGpt2 import *\n",
    "\n",
    "#gpt2\n",
    "\n",
    "GPT2_MODEL = 'gpt2'\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(GPT2_MODEL,\n",
    "                                              do_lower_case=True,\n",
    "                                          cache_dir='transformers_cache')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(GPT2_MODEL,\n",
    "                                        cache_dir='transformers_cache')\n",
    "\n",
    "#eda + gpt2 \n",
    "\n",
    "num_aug = 1\n",
    "file_name = 'posgpt2_eda.tsv'\n",
    "\n",
    "x = f'{output_file}/eda.tsv'\n",
    "train_df = pd.read_csv(x,sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_cposgpt2_and_augment(model,tokenizer,train_df,val_df,output=output_file,\n",
    "                           file_name=file_name,seed = 1234,max_seq_length = 64,sample_num=num_aug,num_train_epochs=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73cd713c-c350-45b2-aa12-4d58a58e9a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.0.6_1/libexec/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cgpt2 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 3.542730174064636\n",
      "avg_loss: 6.6476387739181515\n",
      "avg_loss: 9.653132047653198\n",
      "avg_loss: 12.653635935783386\n",
      "avg_loss: 15.640017247200012\n",
      "avg_loss: 18.61872919559479\n",
      "avg_loss: 21.60526823043823\n",
      "avg_loss: 24.491126914024353\n",
      "avg_loss: 27.43954703807831\n",
      "avg_loss: 30.269526319503782\n",
      "avg_loss: 33.07660957336426\n",
      "avg_loss: 35.88495412826538\n",
      "avg_loss: 38.71126049041748\n",
      "avg_loss: 41.462790350914\n",
      "avg_loss: 44.209820384979245\n",
      "avg_loss: 47.02020929813385\n",
      "avg_loss: 49.76580108642578\n",
      "avg_loss: 52.49969940662384\n",
      "avg_loss: 55.227569055557254\n",
      "avg_loss: 57.96687961578369\n",
      "avg_loss: 60.69389908790588\n",
      "avg_loss: 63.37062427997589\n",
      "avg_loss: 66.12599048137665\n",
      "avg_loss: 68.87326319694519\n",
      "avg_loss: 71.59527648925781\n",
      "avg_loss: 74.32247630119323\n",
      "avg_loss: 76.98949308395386\n",
      "avg_loss: 79.6305905532837\n",
      "avg_loss: 82.31455041408539\n",
      "avg_loss: 84.94262624740601\n",
      "avg_loss: 87.59656219482422\n",
      "avg_loss: 90.2774469256401\n",
      "avg_loss: 92.93563043832779\n",
      "avg_loss: 95.62688305139541\n",
      "avg_loss: 98.24125128507615\n",
      "avg_loss: 100.862939016819\n",
      "avg_loss: 103.47740606546402\n",
      "avg_loss: 106.08345731019973\n",
      "avg_loss: 108.67340083360672\n",
      "Epoch 0, Dev loss 169.21767020225525\n",
      "Saving model. Best dev so far 169.21767020225525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|████████████████                | 1/2 [1:29:23<1:29:23, 5363.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 2.5132253551483155\n",
      "avg_loss: 5.059609823226928\n",
      "avg_loss: 7.49826397895813\n",
      "avg_loss: 9.972965059280396\n",
      "avg_loss: 12.363173596858978\n",
      "avg_loss: 14.846007914543152\n",
      "avg_loss: 17.305765335559844\n",
      "avg_loss: 19.759415414333343\n",
      "avg_loss: 22.172984232902525\n",
      "avg_loss: 24.594798958301546\n",
      "avg_loss: 27.030004720687867\n",
      "avg_loss: 29.45511762857437\n",
      "avg_loss: 31.912397348880766\n",
      "avg_loss: 34.28912814617157\n",
      "avg_loss: 36.7287189078331\n",
      "avg_loss: 39.15927053689957\n",
      "avg_loss: 41.58567893266678\n",
      "avg_loss: 43.94650326967239\n",
      "avg_loss: 46.31462119579315\n",
      "avg_loss: 48.7170184636116\n",
      "avg_loss: 51.1504149889946\n",
      "avg_loss: 53.52029089212417\n",
      "avg_loss: 55.90744333505631\n",
      "avg_loss: 58.28842758655548\n",
      "avg_loss: 60.67099249124527\n",
      "avg_loss: 63.00058187246323\n",
      "avg_loss: 65.4379528260231\n",
      "avg_loss: 67.79528678417206\n",
      "avg_loss: 70.13581414699554\n",
      "avg_loss: 72.47504736185074\n",
      "avg_loss: 74.8851375746727\n",
      "avg_loss: 77.1564173579216\n",
      "avg_loss: 79.50779409646988\n",
      "avg_loss: 81.88032308816909\n",
      "avg_loss: 84.22786557674408\n",
      "avg_loss: 86.58891734361649\n",
      "avg_loss: 88.90222415208817\n",
      "avg_loss: 91.18188475847245\n",
      "avg_loss: 93.53431724786759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████| 2/2 [3:25:19<00:00, 6159.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Dev loss 178.87914180755615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to find the saved model at stas_aug/best_Gpt2.pt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m num_aug \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt2_eda.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrain_cmodgpt2_and_augment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1234\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msample_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cgpt2.py:256\u001b[0m, in \u001b[0;36mtrain_cmodgpt2_and_augment\u001b[0;34m(model, tokenizer, train_df, val_df, output, file_name, seed, max_seq_length, sample_num, num_train_epochs)\u001b[0m\n\u001b[1;32m    252\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), save_model_path)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# augment data using the best model\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m \u001b[43maugment_train_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtrain_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43msample_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cgpt2.py:88\u001b[0m, in \u001b[0;36maugment_train_data\u001b[0;34m(model, tokenizer, train_examples, train_label, output_dir, file_name, prefix, max_seq_length, sample_num, temperature, top_k, top_p, repetition_penalty)\u001b[0m\n\u001b[1;32m     86\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find the saved model at \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_model_path))\n\u001b[1;32m     89\u001b[0m prefix_size \u001b[38;5;241m=\u001b[39m prefix\n\u001b[1;32m     90\u001b[0m save_train_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, file_name)\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to find the saved model at stas_aug/best_Gpt2.pt"
     ]
    }
   ],
   "source": [
    "from cgpt2 import *\n",
    "#gpt2\n",
    "\n",
    "GPT2_MODEL = 'gpt2'\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(GPT2_MODEL,\n",
    "                                              do_lower_case=True,\n",
    "                                          cache_dir='transformers_cache')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(GPT2_MODEL,\n",
    "                                        cache_dir='transformers_cache')\n",
    "\n",
    "#eda + gpt2 \n",
    "\n",
    "num_aug = 1\n",
    "file_name = 'gpt2_eda.tsv'\n",
    "\n",
    "train_cmodgpt2_and_augment(model,tokenizer,train_df,val_df,output=output_file,\n",
    "                           file_name=file_name,seed = 1234,max_seq_length = 64,sample_num=num_aug,num_train_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca1bb8-efc7-4114-ae6c-939ab1d7844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file= 'trec_aug/gpt2_eda.tsv'\n",
    "df = pd.read_csv(file,sep='\\t')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c20e9d-8882-4d51-b300-0ab1ca54a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'trec_aug/eda.tsv'\n",
    "train_df = pd.read_csv(x,sep='\\t')\n",
    "\n",
    "len(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
